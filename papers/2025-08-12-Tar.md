---
title: Vision as a Dialect Unifying Visual Understanding and Generation via Text-Aligned Representations
date: 2025-08-12
tags:
paper: https://arxiv.org/abs/2506.18898
code: https://tar.csuhan.com/
year: 2025
star: 
---
Propose a unified multi modal LLM, based on text-aligned and fully discrete visual representation, allowing the same tokens to support both understanding and generation. This is done by having the VQ codebook be a learned projection of the LLM's (frozen) embedding, grounding the representation in the LLM's latent space. 