---
title: DeepSeekMath Pushing the Limits of Mathematical Reasoning in Open Language Models
date: 2025-05-24
tags:
  - rl
  - post-training
paper: https://arxiv.org/abs/2402.03300
code: https://huggingface.co/docs/trl/main/en/grpo_trainer
year: 2024
star: true
---
Replaces PPOâ€™s KL clip with group-relative clipping, avoiding the need for value function approximation to compute the advantage. Works for both outcome based rewards (response level), and process based rewards (token level). Trained on high quality math data with long-horizon rewards. Evidence that careful on-policy RL can scale when the reward is sparse. 